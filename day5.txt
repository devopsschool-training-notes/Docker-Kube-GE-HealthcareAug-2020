- Compute
- Discovery and LoadBalancers
- Storage - 
- Security 
- Monitoring
	X tools
==========================
Service IP  - POD work

Service Type
		- ClustorIP 
			Is it accessible by all Nodes of the Cluster???
		- NodePort
			- It create a Service of ClustorIP 
			+ It would expose at Node Port as well.
		- LoadBalancer
			- It create a Service of ClustorIP 
			+ It would expose at Node Port as well.
			+ It create Exte LB and Add all Node of the Clustor to ELB.
WORKER IP
=======================
13.232.238.89

kubectl create service clusterip my-cs --tcp=5678:80

app=webserver,software=rajesh

kubectl expose deployment my-dep --port=80 --target-port=80


app=my-dep

kubectl label pods hello-pod-mul app=my-dep
kubectl label pods hello-pod-mul2 app=my-dep --overwrite


 307  vi pod1.yaml
  308  vi pod2.yaml
  309  vi pod1.yaml
  310  more pod2.yaml
  311  clear
  312  more pod1.yaml
  313  clear
  314  ls
  315  kubectl get svc
  316  kubectl get pods
  317  clear
  318  ls
  319  kubectl apply -f pod1.yaml
  320  kubectl apply -f po2.yaml
  321  kubectl apply -f pod2.yaml.yaml
  322  kubectl apply -f pod2.yaml
  323  clear
  324  ls
  325  kubectl get pods
  326  kubectl get pods -o wide
  327  clear
  328  kubectl get pods -o wide
  329  kubectl get pods -o wide --show-labels
  330  kubectl create service -h
  331  clear
  332  kubectl create service clusterip -h
  333  clear
  334  kubectl get pods -o wide --show-labels
  335  curl http://10.44.0.5
  336  curl http://10.44.0.6
  337  clear
  338  kubectl create service clusterip my-cs --tcp=5678:80
  339  kubectl get svc
  340  curl http://10.98.29.191
  341  curl http://10.98.29.191:5678
  342  kubectl get svc --show-lables
  343  kubectl get svc --show-labels
  344  kubectl get pods -o wide --show-labels
  345  kubectl edit svc my-cs
  346  clear
  347  kubectl get pods -o wide --show-labels
  348  kubectl get svc --show-labels
  349  kubectl describe svc my-cs
  350  kubectl edit svc my-cs
  351  clear
  352  kubectl describe svc my-cs
  353  kubectl get svc
  354  curl http://10.98.29.191
  355  curl http://10.98.29.191:5678
  356  clear
  357  curl http://10.98.29.191:5678
  358  clear
  359  curl http://10.98.29.191:5678
  360  watch curl http://10.98.29.191:5678
  361  clear
  362  ls
  363  kubectl create deployment my-dep --image=scmgalaxy/nginx-devopsschoolv1
  364  kubectl get deploy
  365  clear
  366  kubectl scale --replicas=5 deployment/my-dep
  367  ls
  368  kubectl get deploy
  369  kubectl expose -h
  370  c
  371  history
  372  clear
  373  kubectl expose deployment my-dep --port=80 --target-port=80
  374  kubectl get svc
  375  kubectl describe svc my-dep
  376  clear
  377  ls
  378  kubectl get svc
  379  curl http://10.102.253.249
  380  watch curl http://10.102.253.249
  381  clear
  382  ls
  383  kubectl get pods
  384  kubectl describe svc my-dep
  385  clear
  386  ls
  387  kubectl get pods
  388  kubectl label -h
  389  clear
  390  kubectl get pods
  391  kubectl label pods hello-pod-mul app=my-dep
  392  kubectl label pods hello-pod-mul app=my-dep --overwrite
  393  clear
  394  kubectl label pods hello-pod-mul2 app=my-dep --overwrite
  395  kubectl get pods
  396  kubectl describe svc my-dep
  397  cleart
  398  clear
  399  watch curl http://10.102.253.249
  400  history



kubectl expose deployment my-dep --port=80 --target-port=80 --type=NodePort --name=my-nodesvc
kubectl expose deployment my-dep --port=80 --target-port=80 --type=LoadBalancer --name=my-lb


http://ge-1082282632.ap-south-1.elb.amazonaws.com/
ge.devopstraining.xyz





my-lb        LoadBalancer   10.107.24.69     ge-1082282632.ap-south-1.elb.amazonaws.com     80:31549/TCP   10m

  400  history
  401  clear
  402  kubectl get svc
  403  kubectl expose deployment -h
  404  clear
  405  kubectl expose deployment my-dep --port=80 --target-port=80 --type=NodePort
  406  clear
  407  kubectl expose deployment my-dep --port=80 --target-port=80 --type=NodePort --name=my-nodesvc
  408  kubectl get swvc
  409  kubectl get svc
  410  curl http://10.96.240.207
  411  clea
  412  rclear
  413  clear
  414  kubectl get svc
  415  kubectl describe svc my-dep
  416  kubectl export
  417  kubectl expose -h
  418  clear
  419  kubectl expose deployment my-dep --port=80 --target-port=80 --type=LoadBalancer --name=my-lb
  420  kubectl get svc
  421  curl http://10.107.24.69
  422  kubectl create -h
  423  clear
  424  kubectl create service -h
  425  clear
  426  kubectl get svc

kubectl taint node ip-172-31-14-147.ap-south-1.compute.internal node-role.kubernetes.io/master:NoSchedule-

====================================
Storage
========================
Prob is -  PODs are emphe*
========================
How can we have data peristant beyong a lifecycle of the POD?
===============================================================
Answer - k8s volume

k8s volume
	
Physcial Storage where "k8s volume" can be created"
		Block Storage
		- EBS on AWS
		- Azure Disk on Azure
		- Node-in Built storage

		File Storage
		- NFS
		- EFS on AWS
		- cefhs

		OBJECT Storage
		- git repo	
		- s3 

How k8s would understand these tech?
		k8s storage interface
		- many Drivers....

GCEPersistentDisk
AWSElasticBlockStore
AzureFile
AzureDisk
CSI
FC (Fibre Channel)
FlexVolume
Flocker
NFS
iSCSI
RBD (Ceph Block Device)
CephFS
Cinder (OpenStack block storage)
Glusterfs
VsphereVolume
Quobyte Volumes
HostPath (Single node testing only -- local storage is not supported in any way and WILL NOT WORK in a multi-node cluster)
Portworx Volumes
ScaleIO Volumes
StorageOS
	
===========================================================================

How can we make K8s Volume available in Clustor for PODS?
=======================================================

Provisioning ==> 	BINDING 			==> USING ==> Reclaiming
==============================================================
admin			user	     			user
=================================================
Persistent Volumes	persistentvolumeclaims		pod.spec.volume	
							pod.spec.containers.volumemounts.
Create a pool of vol.



HostPath
=======================================
https://www.devopsschool.com/blog/persistentvolume-persistentvolumeclaim-volumes-using-hostpath/




kind: PersistentVolume
apiVersion: v1
metadata:
  name: rajesh-pv1
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/devopsschool"

kind: PersistentVolume
apiVersion: v1
metadata:
  name: rajesh-pv2
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 2Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/tmp/devopsschool"


apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rajeshpvc
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi


apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: rajeshpvc1
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 3Gi


kind: Pod
apiVersion: v1
metadata:
  name: task-pv-pod
spec:
  containers:
    - name: task-pv-container
      image: scmgalaxy/nginx-devopsschoolv1
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: task-pv-storage
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: rajeshpvc1

 1037  clear
 1038  ls
 1039  mkdir rajesh
 1040  cd rajesh/
 1041  ls
 1042  vi pv1.yaml
 1043  kubectl get pv
 1044  kubectl create -f pv1.yaml
 1045  kubectl get pv
 1046  vi pv2.yaml
 1047  kubectl create -f pv2.yaml
 1048  kubectl get pv
 1049  clear
 1050  kubectl get pvc
 1051  vi pv1.yaml
 1052  clear
 1053  ls
 1054  vi pvc1.yaml
 1055  kubectl create -f pvc1.yaml
 1056  kubectl get pvc
 1057  kubectl get pv
 1058  vi pvc1.yaml
 1059  kubectl apply -f pvc1.yaml
 1060  clear
 1061  ls
 1062  kubectl get pv
 1063  kubectl get pvc
 1064  vi pvc2.yaml
 1065  kubectl create -f pvc2.yaml
 1066  kubectl get pvc
 1067  kubectl get pv
 1068  kubectl delete pv rajeshpvc1
 1069  kubectl delete pv rajesh-pv2
 1070  ls
 1071  vi pv2.yaml
 1072  kubectl create -f pv2.yaml
 1073  kubectl get pv
 1074  kubectl get pvc
 1075  clear
 1076  kubectl get pvc
 1077  kubectl get pvc pv
 1078  kubectl get pvc
 1079  clear
 1080  ls
 1081  vi pod.yam
 1082  kubectl create -f pod.yam
 1083  kubectl get pods
 1084  kubectl exec task-pv-pod touch /usr/share/nginx/html/index.html
 1085  kubectl get pods -o wide
 1086  clear
 1087  history

==========================================================================
Montioring
=========================
Infra
	Container Moniotring	- cadvisor (Builtin) - https://github.com/google/cadvisor
				docker stats
	Pod Monitoring - heapster ==> metrics-server - https://github.com/kubernetes-sigs/metrics-server
				kubectl top pods
	Node Moniotoring - Prometheus using  Prometheus operators
Log Moniotring
	Container 	-> Logs		
	Kubetlet events	- Logs
	Controller Events - Logs
	===============================
	elk
		Elastic Search - Database aka inverted index + DSL
		Logstash - Parsing - Process and Clean a data
		Beats - Input of Logs.
		Kibana - dashboard


		Beets --> Logstash --> ES <------- Kibana
		==================================
		
==================================================
Authentication and Authorization
================================================
Authentication   =- How can we access K8s?
https://kubernetes.io/docs/reference/access-authn-authz/authentication/
 - CERT

Authorization - What can you do?
https://kubernetes.io/docs/reference/access-authn-authz/authorization/
- RBAC

Role based Access Control








openssl x509 -req -in employee.csr -CA /etc/kubernetes/pki/ca.crt -CAkey /etc/kubernetes/pki/ca.key -CAcreateserial -out /home/centos/rajesh/employee.crt -days 500



kubectl config set-credentials employee --client-certificate=/home/centos/rajesh/employee.crt  --client-key=/home/centos/rajesh//employee.key


=========================================
https://github.com/devopsschool-training-notes/Kubernetes-Tecnotree-Nov-2019/blob/master/SUPERNOTES.TXT



========================
What is helm charts?
======================

yum is package mgmr for RHEL
apt is pack mgmt for Ubu
playstore is pack mgmr for Andoid
Nuge is pack mgmr for windows
================================
Kubenertes - 
	- 40 Create - 20 Update - Delete == 50 commands...
Tool 
	helm
	- command line tool.
		Download a HELM Chart from remote 
		Apply to k8s.

	What is CHAT
	- Collections of YAML
========================================================
https://www.devopsschool.com/kit/master-in-devops-engineering.html


www.RajeshKumar.xyz
		- Email
		- Phone
		- SOcial

















